{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0135c470",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T12:34:40.751144Z",
     "start_time": "2022-11-08T12:34:33.114890Z"
    }
   },
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd896753",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-01T02:46:13.983641Z",
     "start_time": "2022-11-01T02:46:13.967989Z"
    }
   },
   "source": [
    "# 1. Outlier/Anomaly Detection - Apply outlier Detection techniques.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1003e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cap_outliers(array, k=2):\n",
    "    print('Mean',array.mean(),'STD',array.std())\n",
    "    upper_limit = array.mean() + k*array.std()\n",
    "    lower_limit = array.mean() - k*array.std()\n",
    "    print('lower_limit', lower_limit,'upper_limit',upper_limit,)\n",
    "    array[array<lower_limit] = lower_limit\n",
    "    array[array>upper_limit] = upper_limit\n",
    "    return array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e49354",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[num_cols].apply(cap_outliers, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718857d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T10:07:31.060991Z",
     "start_time": "2022-11-08T10:07:31.050740Z"
    }
   },
   "source": [
    "# 2. Missing values in data​ - Cleaning data by finding and replacing missing values using data science libraries.\n",
    "## missing values There are broadly two ways to treat missing values:\n",
    "\n",
    "1. Delete: Delete the missing values\n",
    "2. Impute:\n",
    "* Imputing by a simple statistic: Replace the missing values by another value, commonly the mean, median, mode etc.\n",
    "* Predictive techniques: Use statistical models such as k-NN, SVM etc. to predict and impute missing values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdbf13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_data(df):\n",
    "    for col in median_impute: #df.select_dtypes(include ='float64').columns:\n",
    "        # Imputing with median value\n",
    "        imputer = SimpleImputer(missing_values=np.NaN, strategy='median')\n",
    "\n",
    "        #Storing imputed values for valid data; optional\n",
    "        impute_list.loc[impute_list['Feature name']==col,'impute_value'] = df[col].median()\n",
    "        df[col] = imputer.fit_transform(df[col].values.reshape(-1,1))[:,0]\n",
    "        print(col, 'null values are ', df[col].isna().sum())\n",
    "\n",
    "return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32aa1c8",
   "metadata": {},
   "source": [
    "# Predictive Method KNN\n",
    "https://www.analyticsvidhya.com/blog/2020/07/knnimputer-a-robust-way-to-impute-missing-values-using-scikit-learn/#:~:text=The%20idea%20in%20kNN%20methods,neighbors%20found%20in%20the%20dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce820d32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-08T12:35:04.312818Z",
     "start_time": "2022-11-08T12:34:56.860385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Before performing imputation\n",
      "    Maths  Chemistry  Physics  Biology\n",
      "0   80.0       60.0      NaN     78.0\n",
      "1   90.0       65.0     57.0     83.0\n",
      "2    NaN       56.0     80.0     67.0\n",
      "3   95.0        NaN     78.0      NaN\n",
      "\n",
      "\n",
      "After performing imputation\n",
      " [[80.  60.  68.5 78. ]\n",
      " [90.  65.  57.  83. ]\n",
      " [87.5 56.  80.  67. ]\n",
      " [95.  58.  78.  72.5]]\n"
     ]
    }
   ],
   "source": [
    "# import the KNNimputer class\n",
    "from sklearn.impute import KNNImputer\n",
    "  \n",
    "# create dataset for marks of a student\n",
    "dict = {'Maths':[80, 90, np.nan, 95], \n",
    "        'Chemistry': [60, 65, 56, np.nan], \n",
    "        'Physics':[np.nan, 57, 80, 78],\n",
    "       'Biology' : [78,83,67,np.nan]}\n",
    "  \n",
    "# creating a data frame from the list \n",
    "Before_imputation = pd.DataFrame(dict)\n",
    "#print dataset before imputaion\n",
    "print(\"Data Before performing imputation\\n\",Before_imputation)\n",
    "  \n",
    "# create an object for KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "After_imputation = imputer.fit_transform(Before_imputation)\n",
    "# print dataset after performing the operation\n",
    "print(\"\\n\\nAfter performing imputation\\n\",After_imputation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af0770c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove redundant words from workspace\n",
    "def clear_memory(searchword):\n",
    "    for name in dir():\n",
    "        if name.startswith(searchword):\n",
    "            del globals()[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d604668",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-15T05:20:37.079167Z",
     "start_time": "2022-11-15T05:20:37.061406Z"
    }
   },
   "outputs": [],
   "source": [
    "def replace_pattern(text):\n",
    "    import re\n",
    "    newtext = re.sub('(-| -|- | - )','' ,text)\n",
    "    newtext = newtext.lower()\n",
    "    return newtext\n",
    "\n",
    "# data['Invoice SO Classification'] = data['Invoice SO Classification'].apply(lambda row:replace_pattern(row))\n",
    "\n",
    "# data['invoiceSO_binned'] = np.where(data['Invoice SO Classification'].str.contains(pat = '(resupply)'),\n",
    "#                                     'resupply',\n",
    "#                                     'others')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2765f6",
   "metadata": {},
   "source": [
    "## 3. Duplicate values in data​ - Cleaning data by finding and removing duplicate values using data science libraries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b3da13",
   "metadata": {},
   "source": [
    "## 4. Categorical data to numeric data ​- Transforming categorical data to numerical data using data science libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aabc035b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-15T05:20:41.956737Z",
     "start_time": "2022-11-15T05:20:41.935411Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_dummies(data, cat_cols):\n",
    "    dummy_vars = list()\n",
    "\n",
    "    for i in range(len(cat_cols)):\n",
    "        print(cat_cols[i])\n",
    "        data_dummies = pd.get_dummies(data[cat_cols[i]],\n",
    "                       prefix=cat_cols[i])\n",
    "        data_dummies = data_dummies.apply(lambda x:x.astype(np.int64))\n",
    "\n",
    "        data = pd.concat([data,data_dummies],axis=1)\n",
    "        dummy_vars.extend(data.columns)\n",
    "    print(dummy_vars)\n",
    "    return(data, dummy_vars)\n",
    "  \n",
    "# data_mod = create_dummies(data[imp_vars+y_var],\n",
    "#                                 cols_dummify)[0]\n",
    "# data_mod.drop(cols_dummify, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ca557a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-15T05:17:03.526108Z",
     "start_time": "2022-11-15T05:17:03.513317Z"
    }
   },
   "outputs": [],
   "source": [
    "def label_SO_classification(row):\n",
    "    if row == 'resupply' :\n",
    "        return 'resupply'\n",
    "    elif row == 'setup':\n",
    "        return 'setup'\n",
    "    else: \n",
    "        return 'others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df15eedb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-15T05:21:07.229942Z",
     "start_time": "2022-11-15T05:21:07.204262Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep].astype(np.float64)\n",
    "\n",
    "# data_mod = clean_dataset(data_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34dbc53",
   "metadata": {},
   "source": [
    "## 5. Group data based on values - In a single dataset, grouping data using data science libraries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe312d0",
   "metadata": {},
   "source": [
    "## 6. Concatenate data along an axis ​- Concatenating data using Python data science libraries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edf3145",
   "metadata": {},
   "source": [
    "## 7. Merge multiple sets of data into a single dataset​ - Joining multiple sets of data using data science libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7825d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79356019",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
